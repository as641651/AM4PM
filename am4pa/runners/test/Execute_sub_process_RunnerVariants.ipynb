{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2306ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef74f14",
   "metadata": {},
   "source": [
    "### Execute sub process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a8351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    \n",
    "class ExecuteSubProcess:\n",
    "    def __init__(self, backend_manager=None):\n",
    "        self.backend_manager = backend_manager\n",
    "    \n",
    "    def process_return_codes_from_subprocesses(self, ret, msg=\"\"):\n",
    "        \"\"\"return code 0: successful execution of the subprocess\n",
    "        return code -1: Unsuccessful execution of the subprocess\n",
    "        Subprocess error code is the return code from the subprocess\"\"\"\n",
    "        if ret == 0:\n",
    "            print(bcolors.OKGREEN + \"Success: {}\".format(msg) + bcolors.ENDC)\n",
    "            return 0\n",
    "        else:\n",
    "            print(bcolors.FAIL + \"Error: {}\\nSub process error code: {}\".format(msg, ret) + bcolors.ENDC)\n",
    "            return -1  \n",
    "        \n",
    "    def execute_subprocess_local(self, call, msg=\"\"):\n",
    "        \"\"\"call a python sub process\"\"\"\n",
    "        print(call)\n",
    "        completed_proccess = subprocess.run(call)\n",
    "        ret = completed_proccess.returncode\n",
    "        return self.process_return_codes_from_subprocesses(ret, msg)\n",
    "    \n",
    "    def execute_subprocess_backend(self, cmd, msg=\"\"):\n",
    "        \"\"\"submit a backend command to a backend manager\"\"\"\n",
    "        if self.backend_manager:\n",
    "            stdout, ret = self.backend_manager.run_cmd(cmd)\n",
    "            print(stdout.readlines())\n",
    "            return self.process_return_codes_from_subprocesses(ret, msg)\n",
    "        else:\n",
    "            print(bcolors.FAIL + \"No backend manager\" + bcolors.ENDC)\n",
    "            return -1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76902672",
   "metadata": {},
   "source": [
    "### Runner\n",
    "\n",
    "Calls a script file in a specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "864c38db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunnerVariants(ExecuteSubProcess):\n",
    "    def __init__(self,operand_sizes, \n",
    "                 script_dir,\n",
    "                 threads=4,\n",
    "                 backend_manager=None,\n",
    "                 backend_commands=None):\n",
    "        \"\"\"\n",
    "        Runners are objects that executes an external command (such as calling a python or julia or bash script)\n",
    "        \n",
    "        RunnerVariants class calls scripts that does the following:\n",
    "            1. Call a script that generates code for variant algorithms.\n",
    "            2. Call a script that executes the variant algorithms and outputs a csv file consisting of time measurements\n",
    "            3. Call a script that generates another script which defines cretain measurement strategy \n",
    "            (such as measuring only a subset of algorithms.)\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__(backend_manager)\n",
    "        \n",
    "        self.script_dir = script_dir\n",
    "        self.operand_sizes = operand_sizes\n",
    "        self.operands_dir_name = \"_\".join(self.operand_sizes)\n",
    "        self.operands_dir = os.path.join(self.script_dir,\n",
    "                                     \"experiments\",\n",
    "                                     self.operands_dir_name)\n",
    "\n",
    "        self.backend_commands = backend_commands\n",
    "        self.threads = threads\n",
    "        # In order to check the status of jobs submitted to a bacth system, \n",
    "        # job name should match with the job name mentioned in the bacth script\n",
    "        self.job_name = \"{}_T{}\".format(self.operands_dir_name, self.threads)\n",
    "\n",
    "\n",
    "    def generate_variants_for_measurements(self, generation_script):\n",
    "        \"\"\"calls a script that generates variants\"\"\"\n",
    "        script_path = os.path.join(self.script_dir, generation_script)\n",
    "        args = self.operand_sizes + [\"--threads={}\".format(self.threads)]\n",
    "        msg = \"{} run: Generate variants\"\n",
    "        if not self.backend_manager:\n",
    "            call = [\"python\", script_path] + args\n",
    "            ret = self.execute_subprocess_local(call, msg.format(\"Local\"))\n",
    "            return ret\n",
    "        else:\n",
    "            cmd = self.backend_commands.build_cmd(\"python\", script_path, \" \".join(args))\n",
    "            ret = self.execute_subprocess_backend(cmd, msg.format(\"Backend interactive\"))\n",
    "            return ret\n",
    "\n",
    "    def measure_variants(self, app, runner_script, submit_cmd=None):\n",
    "        \"\"\"\n",
    "        executes a script that measures the variants and generates an output file.txt\n",
    "        The measurement can be done either locally, in the backend interactively or submnitted \n",
    "        to a batch system in the backend.\n",
    "        \"\"\"\n",
    "        runner_path = os.path.join(self.operands_dir, runner_script)\n",
    "        msg = \"{machine} run: \"+\"Measurements from {script}\".format(script=runner_script)\n",
    "        if not self.backend_manager:\n",
    "            if os.path.exists(runner_path):\n",
    "                print(\"Running Measurements locally\")\n",
    "                call = [app, runner_path]\n",
    "                ret = self.execute_subprocess_local(call, msg.format(machine=\"Local\"))\n",
    "                return ret\n",
    "            else:\n",
    "                print(bcolors.FAIL + \"File not found: \"+ msg.format(machine=\"Local\") + bcolors.ENDC)\n",
    "                return -1\n",
    "        else:\n",
    "            if not submit_cmd:\n",
    "                print(\"Running Measurements Backend interactive\")\n",
    "                cmd = self.backend_commands.build_cmd(app, runner_path)\n",
    "                ret = self.execute_subprocess_backend(cmd, msg.format(machine=\"Backend interactive\"))\n",
    "                return ret\n",
    "            else:\n",
    "                print(\"Running Measurements Backend batch\")\n",
    "                cmd = self.backend_commands.submit_job_cmd(submit_cmd, app, runner_path)\n",
    "                ret = self.execute_subprocess_backend(cmd, msg.format(machine=\"Backend batch\"))\n",
    "                return ret\n",
    "\n",
    "    \n",
    "    def generate_measurements_script(self, generate_measurement_script, variants, run_id, reps):\n",
    "        script_path = os.path.join(self.operands_dir, generate_measurement_script)\n",
    "        cmd_args = \"--algs {algs} --rep {rep} --threads {threads} --id {run_id}\".format(algs=\" \".join(variants),\n",
    "                                                                                        rep=reps,\n",
    "                                                                                        threads=self.threads,\n",
    "                                                                                        run_id=run_id)\n",
    "        msg = \"{machine} run: \" + \"Generate Measurement script {run_id}\".format(run_id=run_id)\n",
    "        if not self.backend_manager:\n",
    "            if os.path.exists(script_path):\n",
    "                call = [\"python\", script_path] + cmd_args.split()\n",
    "                ret = self.execute_subprocess_local(call, msg.format(machine=\"Local\"))\n",
    "                return ret\n",
    "            else:\n",
    "                print(bcolors.FAIL + \"File not found: \"+ msg.format(machine=\"Local\") + bcolors.ENDC)\n",
    "                return -1\n",
    "        else:\n",
    "            cmd = self.backend_commands.build_cmd(\"python\", script_path, cmd_args)\n",
    "            ret = self.execute_subprocess_backend(cmd, msg.format(machine=\"Backend interactive\"))\n",
    "            return ret           \n",
    "\n",
    "    def clean(self):\n",
    "        \"\"\"remove arguments folder\"\"\"\n",
    "        if not self.backend_manager:\n",
    "            if os.path.exists(self.operands_dir):\n",
    "                shutil.rmtree(self.operands_dir)\n",
    "            else:\n",
    "                print(bcolors.FAIL + \"Folder not found: {}\".format(self.operands_dir) + bcolors.ENDC)\n",
    "                return -1\n",
    "        else:\n",
    "            cmd = \"rm -rf {}\".format(self.operands_dir)\n",
    "            ret = self.execute_subprocess_backend(cmd, msg=\"Removing directory {}\".format(self.operands_dir))\n",
    "            return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d025d2",
   "metadata": {},
   "source": [
    "### Local measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a514eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "operand_sizes = [\"75\",\"75\",\"6\",\"75\",\"75\"]\n",
    "script_dir = \"sample_generation/\"\n",
    "runner_local = RunnerVariants(operand_sizes, script_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42842ac9",
   "metadata": {},
   "source": [
    "#### 1. Generate variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2611ac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'sample_generation/generate-variants-linnea.py', '75', '75', '6', '75', '75', '--threads=4']\n",
      "New solution:.............2.02e+05\n",
      "No further generation steps possible.\n",
      "----------------------------------\n",
      "Number of nodes:                 8\n",
      "Solution nodes:                  1\n",
      "Data:                     1.78e+04\n",
      "Best solution:            2.02e+05\n",
      "Intensity:                    11.4\n",
      "Number of algorithms:            6\n",
      "Generated Variants.\n",
      "\u001b[92mSuccess: Local run: Generate variants\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner_local.generate_variants_for_measurements(generation_script=\"generate-variants-linnea.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c69b74",
   "metadata": {},
   "source": [
    "#### 2. Measure variants (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73fbedc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Measurements locally\n",
      "['julia', 'sample_generation/experiments/75_75_6_75_75/runner.jl']\n",
      "\u001b[92mSuccess: Local run: Measurements from runner.jl\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner_local.measure_variants(app=\"julia\", runner_script=\"runner.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79ca30b",
   "metadata": {},
   "source": [
    "#### 3. Generate custom measurement script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af1d9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_script = \"generate-measurements-script.py\"\n",
    "variants = ['algorithm0', 'algorithm1']\n",
    "reps = 3\n",
    "run_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "345c6312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'sample_generation/experiments/75_75_6_75_75/generate-measurements-script.py', '--algs', 'algorithm0', 'algorithm1', '--rep', '3', '--threads', '4', '--id', '0']\n",
      "\u001b[92mSuccess: Local run: Generate Measurement script 0\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner_local.generate_measurements_script(measurements_script, variants, run_id, reps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8138ba7f",
   "metadata": {},
   "source": [
    "#### 4. Measure variants (by calling the custom script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b4455ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Measurements locally\n",
      "['julia', 'sample_generation/experiments/75_75_6_75_75/runner_competing_0.jl']\n",
      "\u001b[92mSuccess: Local run: Measurements from runner_competing_0.jl\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner_competing_script = \"runner_competing_0.jl\"\n",
    "runner_local.measure_variants(app=\"julia\", runner_script=runner_competing_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92e55c",
   "metadata": {},
   "source": [
    "#### 5. Remove the directories generated by the runner\n",
    "\n",
    "This removes the generated variants and the measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d213ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner_local.clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5c0cf2",
   "metadata": {},
   "source": [
    "### Backend measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95784548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend_manager import BackendManager,Commands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a050e824",
   "metadata": {},
   "source": [
    "#### 1. Instantiate a backend manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f94653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = BackendManager(server=\"login18-1.hpc.itc.rwth-aachen.de\", uname=\"as641651\")\n",
    "bm.connect()\n",
    "cmds = Commands(source=\"~/.analyzer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510fcf8b",
   "metadata": {},
   "source": [
    "### Interactive \n",
    "\n",
    "#### 2. Generate variants interactively "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dea4fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "operand_sizes = [\"75\",\"75\",\"6\",\"75\",\"75\"]\n",
    "script_dir = \"sample_generation/\"\n",
    "generation_script = \"generate-variants-linnea.py\"\n",
    "runner = RunnerVariants(operand_sizes, script_dir,backend_manager=bm, backend_commands=cmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b7c3707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source ~/.analyzer; cd sample_generation; python generate-variants-linnea.py 75 75 6 75 75 --threads=4\n",
      "['New solution:.............2.02e+05\\n', 'No further generation steps possible.\\n', '----------------------------------\\n', 'Number of nodes:                 8\\n', 'Solution nodes:                  1\\n', 'Data:                     1.78e+04\\n', 'Best solution:            2.02e+05\\n', 'Intensity:                    11.4\\n', 'Number of algorithms:            6\\n', 'Generated Variants.\\n']\n",
      "\u001b[92mSuccess: Backend interactive run: Generate variants\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ret = runner.generate_variants_for_measurements(generation_script=generation_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5162fe29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74063c28",
   "metadata": {},
   "source": [
    "#### 3. Measure variants interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5be96d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Measurements Backend interactive\n",
      "source ~/.analyzer; cd sample_generation/experiments/75_75_6_75_75; julia runner.jl \n",
      "[]\n",
      "\u001b[92mSuccess: Backend interactive run: Measurements from runner.jl\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.measure_variants(app=\"julia\", runner_script=\"runner.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523d526a",
   "metadata": {},
   "source": [
    "#### 4. Generate measurement script interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af571c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "measurements_script = \"generate-measurements-script.py\"\n",
    "variants = ['algorithm0', 'algorithm1']\n",
    "reps = 3\n",
    "run_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9d7bac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source ~/.analyzer; cd sample_generation/experiments/75_75_6_75_75; python generate-measurements-script.py --algs algorithm0 algorithm1 --rep 3 --threads 4 --id 0\n",
      "[]\n",
      "\u001b[92mSuccess: Backend interactive run: Generate Measurement script 0\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.generate_measurements_script(measurements_script, variants, run_id, reps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624efe8",
   "metadata": {},
   "source": [
    "#### 5. Run measurement script interactively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c859e9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Measurements Backend interactive\n",
      "source ~/.analyzer; cd sample_generation/experiments/75_75_6_75_75; julia runner_competing_0.jl \n",
      "[]\n",
      "\u001b[92mSuccess: Backend interactive run: Measurements from runner_competing_0.jl\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner_competing_script = \"runner_competing_0.jl\"\n",
    "runner.measure_variants(app=\"julia\", runner_script=runner_competing_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457bb72c",
   "metadata": {},
   "source": [
    "### Batch system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b8652b",
   "metadata": {},
   "source": [
    "#### 6. Generate another measurement script (interactively)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44a20211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source ~/.analyzer; cd sample_generation/experiments/75_75_6_75_75; python generate-measurements-script.py --algs algorithm0 algorithm1 --rep 3 --threads 4 --id 1\n",
      "[]\n",
      "\u001b[92mSuccess: Backend interactive run: Generate Measurement script 1\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = 1\n",
    "runner.generate_measurements_script(measurements_script, variants, run_id, reps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7940b48a",
   "metadata": {},
   "source": [
    "#### 7. Measure variants by submitting to a batch system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eaebb64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Measurements Backend batch\n",
      "source ~/.analyzer; cd sample_generation/experiments/75_75_6_75_75; sbatch submit.sh julia 'runner_competing_1.jl '\n",
      "['Submitted batch job 28807909\\n']\n",
      "\u001b[92mSuccess: Backend batch run: Measurements from runner_competing_1.jl\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_cmd = \"sbatch submit.sh\"\n",
    "runner_competing_script = \"runner_competing_1.jl\"\n",
    "runner.measure_variants(app=\"julia\", runner_script=runner_competing_script, submit_cmd=submit_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a194dcaa",
   "metadata": {},
   "source": [
    "#### 8. Check status of the submitted job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2a7959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          28807909        ih               75_75_6_75_75_T4 as641651  RUNNING       0:05   3:00:00      1 linuxihdc074\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.check_slrum_status(runner.job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d16a7",
   "metadata": {},
   "source": [
    "#### 9. Check if the required output file from running the measurement script has been generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48c0b7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm.check_if_file_exists(os.path.join(runner.operands_dir, \"run_times_competing_1.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78594b8c",
   "metadata": {},
   "source": [
    "#### 10. Remove the variants directory and the measurement  files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d02ff9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm -rf sample_generation/experiments/75_75_6_75_75\n",
      "[]\n",
      "\u001b[92mSuccess: Removing directory sample_generation/experiments/75_75_6_75_75\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1303e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
